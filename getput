#!/usr/bin/python -u

# Copyright 2015 Hewlett-Packard Development Company, L.P.
# Use of this script is subject to HP Terms of Use at
# http://www8.hp.com/us/en/privacy/terms-of-use.html.

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#    http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# debug
#    1 - print some basic stuff. inclucing test starts info
#    2 - show cont/obj names on calls
#    4 - report container header info
#    8 - show name of container being used
#   16 - show inputs for starting multiprocessing
#   32 - show trandIDs/latencies, only make sense for small values of -n
#   64 - show connection information
#  128 - trace execution to log in /tmp
#  256 - report end of test/set/proc sleeps
# 1024 - report object etag

# logops masks
#   1 - log all latencies
#   2 - log traces [type 3 calls]
#   4 - log latencies > :latency

import sys
import os
import re
import struct
import random
import requests
import signal
import socket
import string
import time
import inspect
import cStringIO
import requests
import md5
import hashlib
from random import randint
from optparse import OptionParser, OptionGroup
from multiprocessing import Pool
from urlparse import urlparse
from swiftclient import Connection
from swiftclient import ClientException
from swiftclient import put_object


# Handy for tracing execution of getput itself
def logexec(text):

    if debug & 128:
        logfile = '/tmp/getput-exec-%s.log' % (time.strftime('%Y%m%d'))
        log = open(logfile, 'a')
        log.write('%s %s\n' % (time.strftime('%H:%M:%S', time.gmtime()), text))
        log.close()


def exclogger(text):

    exc = open(exclog, 'a')
    exc.write("%s\n" % text)
    exc.close()


def error(text, exit_flag=True):
    """
    Main error reporting, usually exits
    """

    print "Error -- Host: %s getput: %s" % (hostname, text)
    if exit_flag:
        sys.exit(0)


def build_object():
    """
    build a fixed length non-compressible object (unless --objopts
    is 'c') based on size specified by -s
    """

    global md5_digest

    # build a fixed size object of appropriate size with RANDOM bytes so we can
    # be sure they all get transfered and not compressed, but if '--objopts c'
    # use all the same so we WILL.  join() a lot faster than +
    temp = ''
    count = 0
    if not options.objopts or not re.search('c', options.objopts):
        while (count < (32 * 1024)):
            num = int(random.random() * 255)
            temp = ''.join([temp, struct.pack('B', num)])
            count = count + 1
    else:
        temp = ' ' * 32 * 1024

    # replicate it exponentially for speed
    fixed_object = temp
    while (len(fixed_object) < osize):
        fixed_object = ''.join([fixed_object, fixed_object])

    # trim it down if necessary
    fixed_object = fixed_object[:osize]

    m = md5.new()
    m.update(fixed_object)
    md5_digest = m.hexdigest()
    if debug & 1024:
        print "Obj MD5:", md5_digest

    return(fixed_object)


def md5check(oper, cname, objname, response, md5_digest):

    etag = response['headers']['etag']
    if etag != md5_digest:
        txid = response['headers']['x-trans-id']
        print "MD5 Error - on %s, TransID: %s for %s/%s, %s != %s" % \
            (oper, txid, cname, objname, md5_digest, etag)

def reset_last(num_procs):
    """
    Sets the ending object numbers for each process to get, put or delete

    some explanation needed...  last[] contains the max number of objects to
    PUT, GET or DELETE per process.  In the case of multiple sets of tests,
    these need to be reset to the original value specified with -n and if a
    single value spread across all procs. Since a PUT test also resets last[]
    to contain actual number of objects so GET/DEL will need to know how many
    there are.  The errors can only happen looking at original values of -n.
    """

    global last

    last = []
    if options.nobjects and re.search(':', options.nobjects):
        for string in options.nobjects.split(':'):
            try:
                last.append(int(string))
            except ValueError:
                error('-n must be a set of : separated integers')
    else:
        for i in range(num_procs):
            # reset everything to what was specified with -n and if not there
            # we already know there's a runtime so set a huge max objects
            if options.nobjects:
                numobj = int(options.nobjects)
            else:
                numobj = 999999

            try:
                last.append(numobj)
            except ValueError:
                error('-n must be an integer')


def getenv(varname):
    """
    get value for environment variable
    """

    try:
        value = os.environ[varname]
    except KeyError:
        value = ''
    return(value)


def parse_creds(creds_file=None):
    """
    parse credentials either from environment OR credentials file
    """

    # remember, --creds overrides environment
    stnum = 0
    stvars = {}
    for varname in ['ST_AUTH', 'ST_USER', 'ST_KEY']:
        stvars[varname] = getenv(varname)
        if stvars[varname] != '':
            stnum += 1

    osnum = 0
    osvars = {}
    for varname in ['OS_AUTH_URL', 'OS_USERNAME', 'OS_PASSWORD', \
                        'OS_TENANT_ID', 'OS_TENANT_NAME', \
                        'OS_PROJECT_NAME', 'OS_PROJECT_ID', \
                        'OS_PROJECT_DOMAIN_NAME', 'OS_PROJECT_DOMAIN_ID', \
                        'OS_USER_DOMAIN_NAME', 'OS_USER_DOMAIN_ID', \
                        'OS_REGION_NAME', 'OS_SERVICE_TYPE', 'OS_AUTH_VERSION', \
                        'OS_ENDPOINT_TYPE', 'OS_IDENTITY_API_VERSION', \
                        'SWIFTCLIENT_INSECURE', 'OS_CACERT', 'OS_CERT']:
        osvars[varname] = getenv(varname)
        if osvars[varname] != '':
            osnum += 1

    if creds_file:
        try:
            f = open(creds_file, 'r')
            for line in f:
                if re.match('\#|\s*$', line):
                    continue
                line = line.rstrip('\n')

                search = re.search('(ST|OS|SWIFTCLIENT)_(.*)=(.*)', line)
                if search:
                    value = search.group(3).strip(";'\"")
                    if search.group(1) == 'ST':
                        stvars["ST_" + search.group(2)] = value
                        stnum += 1
                    elif search.group(1) == 'OS':
                        osvars["OS_" + search.group(2)] = value
                        osnum += 1
                    elif search.group(1) == 'SWIFTCLIENT':
                        osvars["SWIFTCLIENT_" + search.group(2)] = value
                        osnum += 1

        except IOError, err:
            error("Couldn't read creds file: " + creds_file)

    if stnum > 0 and  osnum > 0:
        error('you have both ST_ and OS_style varibles defined' + \
                  ' in your environment and you must only have 1 type')
    if stnum > 0 and stnum != 3:
        error('you have at least 1 ST_ style variable defined but not all 3')
    if osnum > 0:
        if osvars['OS_AUTH_URL'] == '' or osvars['OS_USERNAME'] == '' \
                                       or osvars['OS_PASSWORD'] == '':
            error('your environment has at least 1 OS_ style variable ' + \
                  'defined but not OS_AUTH_URL, OS_USERNAME or OS_PASSWORD')
        if osvars['OS_TENANT_NAME'] == '' and osvars['OS_TENANT_ID'] == '' \
                                          and osvars['OS_PROJECT_NAME'] == ''\
                                          and osvars['OS_PROJECT_ID'] == '':
            error('your environment has at least 1 OS_ style variable ' + \
                  'defined but not OS_TENANT_NAME, OS_TENANT_ID or ' + \
                  'OS_PROJECT_NAME, OS_PROJECT_ID')

    username = password = authurl = ''

    if stnum > 1:
        authurl = stvars['ST_AUTH']
        username = stvars['ST_USER']
        password = stvars['ST_KEY']
    elif osnum > 1:
        authurl = osvars['OS_AUTH_URL']
        del osvars['OS_AUTH_URL']
        username = osvars['OS_USERNAME']
        del osvars['OS_USERNAME']
        password = osvars['OS_PASSWORD']
        del osvars['OS_PASSWORD']

    return((authurl, username, password, osvars))


def main(argv):
    """
    read/parse switches
    """

    global debug, options, procset, sizeset, ldist10
    global username, password, authurl, osvars, errmax
    global latexc_min, latexc_max, exclog, excopt, sha_size

    ldist10 = 0
    procset = [1]
    latexc_min = latexc_max = 9999

    parser = OptionParser(add_help_option=False)
    group0 = OptionGroup(parser, 'these are the basic switches')
    group0.add_option('-c', '--cname',    dest='cname',
                      help='container name')
    group0.add_option('-d', '--debug',    dest='debug',
                      help='debugging mask', default=0)
    group0.add_option('-n', '--nobjects', dest='nobjects',
                      help='containter/object numbers as a value OR range')
    group0.add_option('-o', '--obj',      dest='oname',
                      help='object name prefix')
    group0.add_option('-p', '--policy',   dest='policy',
                      help='container storage policy', default='')
    group0.add_option('-r', '--runtime',  dest='runtime',
                      help="runtime in secs")
    group0.add_option('-s', '--size',     dest='sizeset',
                      help='object size(s)')
    group0.add_option('-t', '--tests',    dest='tests',
                      help='tests to run [gpd]')
    group0.add_option('-h', '--help', dest='help',
                      help='show this help message and exit',
                      action='store_true')
    group0.add_option('-v', '--version',  dest='version',
                      help='print version and exit',
                      action='store_true')
    parser.add_option_group(group0)

    groupa = OptionGroup(parser, 'these switches control the output')
    groupa.add_option('--echo',     dest='echo',
                      help='echo command', action='store_true')
    groupa.add_option('--ldist',    dest='ldist',
                      help="report latency distributions at this granularity")
    groupa.add_option('--nohead',   dest='nohead',
                      help="do not print header with results",
                      action='store_true', default=False)
    groupa.add_option('--psum',     dest='psum',
                      help="include process summary in output",
                      action='store_true', default=False)
    groupa.add_option('--putsperproc', dest='putsperproc',
                      action='store_true', default=False,
                      help='list numbers of puts by each process')
    parser.add_option_group(groupa)

    groupc = OptionGroup(parser, 'these switches effect behavior')
    groupc.add_option('--cont-nodelete', dest='cont_nodelete',
                      help="do not delete container after a delete test",
                      action='store_true', default=False)
    groupc.add_option('--ctype',    dest='ctype', default='byproc',
                      help="container type: shared|bynode|byproc")
    groupc.add_option('--errmax',   dest='errmax',
                      help="quit after this number of errors, [def=5]",
                      default=5)
    groupc.add_option('--exclog',   dest='exclog',
                      help="write latencies to log instead or terminal")
    groupc.add_option('--extra',   dest='extra',
                       help="defined value for X-Trans-Id-Extra")
    groupc.add_option('--headers',   dest='headers',
                       help="additional headers")
    groupc.add_option('--insecure', dest='insecure',
                      action='store_true', default=False,
                      help="allow access without verifying SSL certs")
    groupc.add_option('--latexc',   dest='latexc',
                      help="stop when max latency matches exception")
    groupc.add_option('--logops',   dest='logops',
                      help="log latencies for all operations",
                      default='0')
    groupc.add_option('--objopts',    dest='objopts', default='',
                      help='object options [acfru]')
    groupc.add_option('--objoffset',    dest='objoffset', default='0',
                      help='object number offset for flat hierarchies')
    groupc.add_option('--objseed',    dest='objseed', default='0',
                      help='seed for random object naming')
    groupc.add_option('--preauthtoken', dest='preauthtoken',
                      default='',
                      help="use this rather then the one returned")
    groupc.add_option('--procs',    dest='procset',
                      help="number of processes to run")
    groupc.add_option('--proxies',   dest='proxies', default='',
                      help='bypass load balancer and connect directly')
    groupc.add_option('--quiet',   dest='quiet', default=False,
                      help='suppress api errors & sync time warnings',
                      action='store_true')
    groupc.add_option('--range',   dest='range', default='',
                      help='get object by this range')
    groupc.add_option('--repeat',   dest='repeats',
                      help='number of time to repeat --num tests')
    groupc.add_option('--retries',  dest='retries', default='5',
                      help='number of time to retry failed test')
    groupc.add_option('--sleeps',   dest='sleeps',
                      help='times to sleep at various test points')
    groupc.add_option('--scheme',   dest='scheme', default='',
                      help='authurl connection scheme, http|https')
    groupc.add_option('--warnexit', dest='warnexit',
                      help='exit on warnings', action='store_true')
    parser.add_option_group(groupc)

    groupb = OptionGroup(parser, 'multi-node access')
    groupb.add_option('--creds',    dest='creds',
                      help='credentials')
    groupb.add_option('--rank',     dest='rank',
                      help='rank among clients, used in obj/container names',
                      default='0')
    groupb.add_option('--sync',     dest='synctime',
                      help='time, in seconds since epoch, to start test')
    groupb.add_option('--utc',     dest='utc',
                      action='store_true', default=False,
                      help='append utc time to container names')
    parser.add_option_group(groupb)

    try:
        (options, args) = parser.parse_args(argv)
    except:
        print 'invalid command'
        sys.exit()

    if options.help:
        parser.print_help()
        sys.exit()

    if options.version:
        print 'getput V%s\n\n%s' % (version, copyright)
        sys.exit()

    #    T h e s e    h a v e    d e f a u l t s
    #    G e t    C r e d e n t i a l s    f r o m    C r e d s    F i l e

    (authurl, username, password, osvars) = parse_creds(options.creds)

    try:
        debug = int(options.debug)
    except:
        error('-d must be an integer')

    try:
        errmax = int(options.errmax)
    except ValueError:
        error('--errmax must be an integer')


    #     R e q u i r e d :   - - t e s t s    &    - - c n a m e

    if username == '' or password == '' or authurl == '':
        error('specify credentials with --creds OR set ST_* variables')

    if options.tests:
        if not (re.match('[,pgdPGD]+\Z', options.tests)):
            error("valid tests are comma separated combinations of: gpd")
    else:
        error('define test list with -t')

    # cname and oname actually defined in init_test()
    if not options.cname:
        error('specify container name with -c')

    if options.objopts:
        # if you include 'r', you can optionally include a length too
        if not re.match('^[acfu]*r\d*[acfu]*$', options.objopts):
            error("--objopts must be a combination of 'acfru'")
        match = re.search('r(\d+)', options.objopts)
        sha_size = 128 if not match else int(match.group(1))

    if options.objoffset and options.objoffset != '0':
        try:
            objoffset = int(options.objoffset)
        except ValueError:
            error("--objoffset must be an integer")
        if re.search('a', options.objopts):
            error("--objnum and append mode are mutually exclusive")
	if not re.search('f', options.objopts):
            error("--objoffset only makes sense for flat hierarchies")
        try:
            objoffset = int(options.objoffset)
        except ValueError:
            error("--objoffset must be an integer")

    #    T e s t    D e p e n d e n t    S w i t c h e s

    if options.range != '':
        if not re.search('g', options.tests):
            error("--range only applies to 'get' tests")
        for value in options.range.split(','):
            if not re.match('\d+-\d+$', value):
                error("range '%s' must be in min-max format" % (value))

    if re.match('[gpd]', options.tests):
        if not options.oname:
            error('get, put and delete tests require object name')

    if options.sizeset:
        if re.search(',', options.sizeset):
            if not re.match('p', options.tests):
                error('multiple obj sizes require PUT test')

        sizeset = []
        for size in options.sizeset.split(','):
            match = re.match('(\d+)([kmg]?\Z)', size, re.I)
            if (match):
                sizeset.append(size)
            else:
                error('object size must be a number OR number + k/m/g')
    else:
        error('object size required')

    #    O p t i o n a l

    if options.procset:
        procset = []
        for proc in options.procset.split(','):
            try:
                procset.append(int(proc))
            except ValueError:
                error('--procs must be an integer')

    if options.ldist:
        try:
            if int(options.ldist) > 3:
                error("--ldist > 3 not supported")
        except ValueError:
            error('--ldist must be an integer')
        ldist10 = 10 ** int(options.ldist)

    if options.runtime:
        if not re.match('\d+$', options.runtime):
            error('--runtime must be an integer')

    if options.ctype != None:
        if not re.match('shared|bynode|byproc', options.ctype):
            error("invalid ctype, expecting: 'shared|bynode|byproc'")

    if options.rank and not re.match('\d+$', options.rank):
        error('--rank must be an integer')

    # initialze last[] for all processes based on first value of -n
    if options.nobjects:
        reset_last(procset[0])
    elif not options.runtime:
        error('specify at least one of -n and/or --runtime')

    if options.repeats and not re.match('\d+$', options.repeats):
        error('-r must be an integer')

    if options.synctime and not re.match('\d+$', options.synctime):
        error('sync time must be an integer')

    if args:
        print "Extra command argument(s):", args
        sys.exit()

    if options.latexc:
        if re.search('-', options.latexc):
            latexc_min, latexc_max = options.latexc.split('-')
        else:
            latexc_min = options.latexc
            latexc_max = 9999

        latexc_min = float(latexc_min)
        latexc_max = float(latexc_max)

    if options.exclog:
        if not options.latexc:
            error('--exclog required --latexc')
        if re.search(':', options.exclog):
            exclog, excopt = options.exclog.split(':')
            if excopt != 'c':
                error('only valid --excopt options is c')
        else:
            exclog = options.exclog
            excopt = ''


def cvtFromKMG(str):
    """
    converts a string containing K, M or G to its equivilent number
    """

    # remember, we already verify sizeset[]
    match = re.match('(\d+)([kmg]?\Z)', str, re.I)
    size = int(match.group(1))
    type = match.group(2).lower()
    if type == '':
        objsize = size
    if type == 'k':
        objsize = size * 1024
    elif type == 'm':
        objsize = size * 1024 * 1024
    elif type == 'g':
        objsize = size * 1024 * 1024 * 1024
    return(objsize)


def cvt2KMG(num):
    """
    converts a string which is a multiple of 1024 to the form: number[KMG]
    """

    # only do this is exact multiple of 1024
    temp = num
    suffix = ''
    if (int(num / 1024) * 1024 == num):
        modifiers = 'kmg'
        while(temp > 1023):
            temp = temp / 1024
            suffix = modifiers[0]
            modifiers = modifiers[1:]
    return(str(temp) + suffix)


native_close = True
if not hasattr(Connection, 'close'):
    native_close = False

    class MyConnection(Connection):

        def close(self):
            if self.http_conn:
                self.http_conn[1].close()


def connect(authurl, username, password, osvars, \
                preauthurl=None, preauthtoken=None):
    """
    make a connection to swift
    """

    if 'OS_AUTH_VERSION' in osvars:
        auth_version = osvars['OS_AUTH_VERSION']
    elif 'OS_IDENTITY_API_VERSION' in osvars:
        auth_version = osvars['OS_IDENTITY_API_VERSION']
    elif re.search('v1.0', authurl):
        auth_version = '1.0'
    elif re.search('v2.0', authurl):
        auth_version = '2.0'
    elif re.search('v3', authurl):
        auth_version = '3'

    # simple 1:1 mapping to parameter value
    cacert = None
    if 'OS_CACERT' in osvars:
        cacert = osvars['OS_CACERT']

    if 'SWIFTCLIENT_INSECURE' in osvars:
        insecure = osvars['SWIFTCLIENT_INSECURE']
    else:
        insecure = options.insecure

    retries = int(options.retries)

    # these get specified in opts dictionary noting BOTH tenant_id
    # and _name must be defined in dictionary
    os_options = {}
    for key, value in osvars.iteritems():
        if value == "":
            continue
        key = key.replace("OS_", "")
        key = key.lower()
        os_options[key] = value

    if preauthurl != None:
        authurl = ''
    if debug & 64:
        print "Connect - User: %s Key: %s Options: %s" % \
            (username, password, os_options)
        print "Connect - Retries: %d AuthVer: %s AuthURL: %s" % \
            (retries, auth_version, authurl)
        print "Connect - Insecure: %s  Cert: %s" % \
            (insecure, cacert)
        print "Connect - PreauthURL: %s PreauthToken: %s" % \
            (preauthurl, preauthtoken)

    # get the connection object
    if preauthurl:
        logexec('connect - PreauthURL: %s  PreauthToken: %s' % \
                    (preauthurl, preauthtoken))
    try:
        response = {}
        if native_close:
            connection = \
                Connection(authurl=authurl,
                             user=username,
                             key=password,
                             auth_version=auth_version,
                             retries=retries,
                             preauthurl=preauthurl,
                             preauthtoken=preauthtoken,
                             insecure=insecure,
                             cacert=cacert,
                             os_options=os_options)
        else:
            connection = \
                MyConnection(authurl=authurl,
                             user=username,
                             key=password,
                             auth_version=auth_version,
                             preauthurl=preauthurl,
                             preauthtoken=preauthtoken,
                             insecure=insecure,
                             cacert=cacert,
                             os_options=os_options)
    except Exception as err:
        import traceback
        print "Connect failure: %s" % err
        logexec('connect() exception: %s %s' % (err, traceback.format_exc()))
        return(-1)

    # Just created the connection object, so make sure we're really connected
    # Errors are very rare, but if something misconfigured we want to know!
    logexec('connected')
    try:
        headers = connection.head_account()
    except Exception as err:
        import traceback
        print "head_account failure: %s" % err
        logexec('head_account() exception: %s %s' % \
                    (err, traceback.format_exc()))

        # I'm not happy with the pattern I'm matching but I've seen
        # at least these 2 types of messages when proxies were set
        # and head_account failed.
        failure = "%s" % err
        if re.search('Not Found|Unable to establish connection', failure):
            print "    => are proxies or the lack of them the problem? <="

        return(-1)

    if debug & 4:
        print "Headers: ", headers
    container_count = int(headers.get('x-account-container-count', 0))

    if debug & 64:
        print "connected!", connection

    return(connection)


def logger(optype=None, data=None, inst=None, test_time=None):
    """
    write operation details to a log file, including start/stop times
    and latencies
    types:
        1 - open log
        2 - latency record
        3 - tracing record
        4 - errors
        9 - close logfile

    mask
        1 - just latencies
        2 - just traces
        4 - exception traces
    """

    global logfiles

    if not logmask:
        return

    if optype == 9:
        logfiles[inst].close()
        return()

    # should we log?
    if optype == 2 and (not logmask & 5) or (optype == 3 and not logmask & 2):
        return()

    if optype == 1:
        # data is actually the name of the test for type 1 call
        filename = '/tmp/getput-%s-%d-%d.log' % (data, inst, int(test_time))
        logfiles[inst] = open(filename, 'w')
    else:
        secs = time.time()
        usecs = '%.3f' % (secs - int(secs))
        now = "%s.%s" % (time.ctime(secs).split()[3], usecs.split('.')[1])
        logfiles[inst].write('%s %f %s\n' % (now, secs, data))
        logfiles[inst].flush()


def api_error(type, instance, cname, oname, err, response=None):
    """
    Report SWIFT api errors
    """

    time_now = time.strftime('%H:%M:%S')
    error_string = '%s %s API Error %d' % (time_now, type, err.http_status)
    try:
	if response:
	    error_string += ' TransID: %s' % response['headers']['x-trans-id']
    except KeyError:
	none
    error_string += ' %s/%s' % (cname, oname)

    if not options.quiet:
        print error_string
    logger(4, 'ApiError: %s ' % err.http_status, instance)


def latcalc(latency, min, max, tot, dist):
    """
    track total latency times and also incrememnt appropriate histogram bucket
    """

    tot = tot + latency
    if latency < min:
        min = latency
    if latency > max:
        max = latency

    # Distribution:  0  1  2  3  4  5 10 20 30 40 50
    # bucket 5 contains values of 5.xxx whereas higher numbered bucket
    # contains values not including that value so bucket 6 goes up to 9.999
    # and 7 up to 19.999
    bucket = int(latency * ldist10)
    if bucket >= 5:
        bucket = int(bucket / 10) + 5
    if bucket > 10:
        bucket = 10
    dist[bucket] = dist[bucket] + 1

    return(min, max, tot)


def reset_url(url, new_address=None):
    """
    reset url's scheme and port based on --scheme
    and optional addresss
    """

    # parse url's scheme, addr, port and path
    new_url = url
    pieces = urlparse(new_url)
    scheme = pieces[0]
    address = pieces[1]
    if re.search(':', address):
        address, port = address.split(':')
    else:
        port = ''
    path = pieces[2]

    # if an address specified, we reset that one
    if new_address:
        address = new_address

    # if user specificed --scheme, we use both the scheme and/or port
    # depending on which are named
    if options.scheme != '':
        pieces = options.scheme.split(':')
        if pieces[0] != '':
            scheme = pieces[0]
        if len(pieces) > 1:
            port = pieces[1]

    new_url = '%s://%s' % (scheme, address)
    if port != '':
        new_url += ':%s' % port
    new_url += path

    if url != new_url and debug & 64:
        print "Reset: %s  To: %s" % (url, new_url)

    return(new_url)


#########################
#    Object Operations
#########################


def get_offset(procs, instance, csize):

    """
    when doing random I/O, the object numbering depends on container type
    and doing it here makes sure consistent for ALL types of operations
    """

    procs = int(procs)
    numobjs = int(options.nobjects)
    if options.ctype == 'shared':
        offset = numobjs * procs * int(options.rank) + numobjs * instance
    elif options.ctype == 'bynode':
        offset = numobjs * instance
    else:
        offset = 0

    # remember, these are mutially exclusive
    objoffset = int(options.objoffset)
    if objoffset > 0:
        offset += objoffset
    elif re.search('a', options.objopts):
        offset += csize

    return(offset)


def put(connection, instance, donetime, cname, csize, oname, random_flag):
    """
    perform PUT operations for 1 process until end time OR requested
    number of operations is reached
    """

    lat_dist = []
    for i in range(11):
        lat_dist.append(0)

    # for stats
    latencies = []

    # we need the cpu counters for when this operation actually starts
    scpu = read_stat()

    t0 = time.time()

    min = 9999
    ops = max = tot = errs = 0
    puts = 1
    retries = 0
    maxputs = last[instance]

    # flat hierarchies are based on rank/proc/instance AND if container
    # already exists it will be appended to
    if re.search('f', options.objopts):
        offset = get_offset(procs, instance, csize)
    logexec('call logger')
    logger(3, 'cname: %s  oname: %s  puts: %d  now: %d  done: %d' % \
               (cname, oname, maxputs, time.time(), donetime), instance)

    if options.headers:
        fields = options.headers.split(':')
        debug_tag = fields[0]
        debug_mask = fields[1]
        debug_width = int(fields[2]) if len(fields)>2 else 1

    fp = cStringIO.StringIO(fixed_object)
    while (puts <= maxputs and time.time() < donetime and errs < errmax):

        # build object name based on object type and number
        if random_flag:
            object_number = randint(1, csize)
        elif re.search('f', options.objopts):
            object_number = offset + puts
        else:
            object_number = puts
        objname = '%s-%d' % (oname, object_number)

        # note that we need the '*' (or any non-numeric char) to prevent the
        # new object name from clashing with others due to the extra digit
        if re.search('r', options.objopts):
            objname = hashlib.sha512(objname + '*' + options.objseed).hexdigest()[0:sha_size]
             
        if debug & 2:
            print "%s PUT CName: %s  OName: %s Inst: %d" % \
                (time.strftime('%H:%M:%S'), cname, objname, instance)

        puts = puts + 1
        t1 = time.time()
        fp.seek(0)
        try:
            response = {}
            logexec("Call PUT")
            headers = {}
            if options.headers:
                headers['X-Debug-Mask'] = '%s%0*s:%s' % (debug_tag, debug_width, object_number, debug_mask)
            if options.extra:
                headers['X-Trans-Id-Extra'] = options.extra
            connection.put_object(cname, objname, fp, osize,
                                  response_dict=response,
                                  headers=headers)
            logexec("PUT succeeded")
            transID = response['headers']['x-trans-id']
            md5check('put', cname, objname, response, md5_digest)

        except ClientException as err:
            # I expect this to be very rare so if token expired just
            # reconnect and retry, treating like any other errors
            errs = errs + 1
            if err.http_status == 401:
                api_error('token expired, retry put', instance, cname, objname, err)
                puts -= 1
                connection = connect(authurl, username, password, osvars, \
                                         preauthurl, preauthtoken)
            else:
                api_error('put', instance, cname, objname, err, response)
            continue

        # this has been a lot of pain, but if we do get a traceback this is the
        # best way I could think of to both record it locally in the exec.log
        # and pass it back to gpmulti if called that way.
        except Exception as err:
            import traceback
            logexec('put_object() exception: %s %s' % \
                        (err, traceback.format_exc()))
            logger(9, '', instance)
            return(['Unexpected Error - put_object() exception: %s' % \
                        err, instance, 0, 0, 0, 0, 0, 0,
                        lat_dist, latencies, scpu, 0])

        ops = ops + 1
        t2 = time.time()
        latency = t2 - t1
        min, max, tot = latcalc(latency, min, max, tot, lat_dist)
        latencies.append(latency)

        tries = connection.attempts
        retries += tries - 1
        if debug & 32:
            print "%f  %f  TransID: %s Latency: %9.6f Tries: %d %s/%s" % \
                (t1, t2, transID, latency, tries, cname, objname)

        # note the size if the latecy can vary by object size
        if logmask & 1 or (logmask & 4 and latency > sizelat[sizenum]):
            logger(2, "%f  %f  %s  %s/%s" %\
                       (t1, latency, transID, cname, objname), instance)

        # let it continue so all the cleanup stuff find objects to delete
        if latency >= latexc_min and latency <= latexc_max:
            start = time.strftime('%Y%m%d %H:%M:%S', time.gmtime(t1))
            text = "%s PUT latency exception: %6.3f secs " \
                "ObjSize: %4s TransID: %s Tries: %d Obj: %s/%s" % \
                (start, latency, size, transID, tries, cname, objname)
            if not options.exclog:
                print "Host: %s -- Warning: %s" % (hostname, text)
                if options.warnexit:
                    break
            else:
                exclogger(text)

    elapsed = time.time() - t0
    logger(3, 'Done!  time: %f ops: %d errs: %d' % \
               (elapsed, ops, errs), instance)
    logger(9, '', instance)

    return(['put', instance, elapsed, ops, min, max, \
                tot, errs, lat_dist, latencies, scpu, retries])


# gets/dels of flat hierarchies are tricky becuase multiple processes can
# be hitting them.  when doing random gets/del, which may soon be obsolete
# now that we have --objopts r, it's ok to calculate a random object number
# but there was no basis for sequental but now that we've added both --offset
# and 'r', we can walk sequentially through container based on pre-sha512
# object names 
def get(connection, instance, donetime, cname, csize, oname, random_flag):
    """
    perform GET operations for 1 process until end time OR requested
    number of operations is reached
    """

    lat_dist = []
    for i in range(11):
        lat_dist.append(0)

    # for stats
    latencies = []

    # we need the cpu counters for when this operation actually starts
    scpu = read_stat()

    t0 = time.time()

    # NOTE - we need to init objsize just in case we don't get any!
    min = 9999
    ops = max = tot = errs = objsize = 0
    gets = 1
    retries = 0
    maxgets = last[instance]

    logexec('call logger')
    logger(3, 'cname: %s  oname: %s  gets: %d  now: %d  done: %d' %
           (cname, oname, maxgets, time.time(), donetime), instance)

    while (gets <= maxgets and time.time() < donetime and errs < errmax):

        objsize = 0

        # build object name based on object type and number
        # noting for now, sequential access for flat hierachies
        # is disallowed and only here as a placeholder
        if random_flag:
            object_number = randint(1, csize)
        elif re.search('f', options.objopts):
            object_number = offset + gets
        else:
            object_number = gets
        objname = '%s-%d' % (oname, object_number)

        if re.search('r', options.objopts):
            objname = hashlib.sha512(objname + '*' + options.objseed).hexdigest()[0:sha_size]

        if debug & 2:
            print "%s GET CName: %s  OName: %s Inst: %d" % \
                (time.strftime('%H:%M:%S'), cname, objname, instance)

        gets = gets + 1
        t1 = time.time()
        try:
            response = {}
            body = []
            headers = {}
            if options.range != '':
                headers['Range'] = 'bytes=%s' % options.range
            if options.extra:
                headers['X-Trans-Id-Extra'] = options.extra
            headers, body = connection.get_object(cname, objname,
                                                  headers=headers,
                                                  response_dict=response,
                                                  resp_chunk_size=65536)
            transID = response['headers']['x-trans-id']

        except ClientException as err:
            errs = errs + 1
            if err.http_status == 401:
                api_error('token expired, retry get', instance, cname, objname, err)
                gets -= 1
                connection = connect(authurl, username, password, osvars, \
                                         preauthurl, preauthtoken)
            else:
                api_error('get', instance, cname, objname, err, response)
            continue

        except Exception as err:
            import traceback
            logexec('get_object() exception: %s %s' %\
                        (err, traceback.format_exc()))
            logger(9, '', instance)
            return(['Unexpected Error - get_object() exception: %s' % \
                        err, instance, 0, 0, 0, 0, 0, 0,
                        lat_dist, latencies, scpu, 0])

        # continue reading until we have whole object, noting the assumption
        # if etag checking is fast enough for swift to do all the time, so can I
        m = md5.new()
        for chunk in body:
            m.update(chunk)
            if len(chunk) == 0:
                break
            else:
                objsize += len(chunk)

        ops = ops + 1
        t2 = time.time()
        latency = t2 - t1
        min, max, tot = latcalc(latency, min, max, tot, lat_dist)
        latencies.append(latency)
        if options.range == '':
            md5check('get', cname, objname, response, m.hexdigest())

        tries = connection.attempts
        retries += tries - 1
        if debug & 32:
            print "%f  %f  TransID: %s Latency: %9.6f Tries: %d %s/%s ObjSize: %d" % \
                (t1, t2, transID, latency, tries, cname, objname, objsize)

        if logmask & 1 or (logmask & 4 and latency > sizelat[sizenum]):
            logger(2, "%f  %f  %s  %s/%s" % \
                       (t1, latency, transID, cname, objname), instance)

        if latency >= latexc_min and latency <= latexc_max:
            start = time.strftime('%Y%m%d %H:%M:%S', time.gmtime(t1))
            text = "%s GET latency exception: %6.3f secs " \
                "ObjSize: %4s TransID: %s Tries: %d Obj: %s/%s" % \
                (start, latency, size, transID, tries, cname, objname)
            if not options.exclog:
                print "Host: %s -- Warning: %s" % (hostname, text)
                if options.warnexit:
                    break
            else:
                exclogger(text)

    elapsed = time.time() - t0
    logger(3, 'Done!  time: %f ops: %d errs: %d' % \
               (elapsed, ops, errs), instance)
    logger(9, '', instance)

    return(['get', instance, elapsed, ops, min, max, \
                tot, errs, lat_dist, latencies, scpu, retries])


def delobj(connection, instance, donetime, cname, csize, oname, random_flag):
    """
    perform DEL operations for 1 process until end time OR requested
    number of operations is reached
    """

    lat_dist = []
    for i in range(11):
        lat_dist.append(0)

    # for stats
    latencies = []

    # we need the cpu counters for when this operation actually starts
    scpu = read_stat()

    t0 = time.time()

    min = 9999
    min = 9999
    ops = max = tot = errs = 0
    dels = 1
    retries = 0
    maxdels = last[instance]

    logger(3, 'cname: %s  oname: %s  dels: %d  now: %d  done: %d' %
           (cname, oname, maxdels, time.time(), donetime), instance)

    while (dels <= maxdels and time.time() < donetime and errs < errmax):

        # build object name based on object type and number
        # like GET, sequential deletes of flat containers is disallowed
        if random_flag:
            object_number = randint(1, csize)
        elif re.search('f', options.objopts):
            object_number = offset + gets
        else:
            object_number = dels
        objname = '%s-%d' % (oname, object_number)

        if re.search('r', options.objopts):
            objname = hashlib.sha512(objname + '*' + options.objseed).hexdigest()[0:sha_size]


        if debug & 2:
            print "%s DEL CName: %s  OName: %s Inst: %d" %\
                (time.strftime('%H:%M:%S'), cname, objname, instance)

        dels = dels + 1
        t1 = time.time()
        try:
            response = {}
            connection.delete_object(cname, objname,
                                     response_dict=response)
            transID = response['headers']['x-trans-id']

        except ClientException as err:
            errs = errs + 1
            if err.http_status == 401:
                api_error('token expired, retry del', instance, cname, objname, err)
                dels -= 1
                connection = connect(authurl, username, password, osvars, \
                                         preauthurl, preauthtoken)
            else:
                api_error('del', instance, cname, objname, err, response)
            continue


        except Exception as err:
            import traceback
            logexec('delete_object() exception: %s %s' % \
                        (err, traceback.format_exc()))
            logger(9, '', instance)
            return(['Unexpected Error - delete_object() exception: %s' % \
                        err, instance, 0, 0, 0, 0, 0, 0, \
                        lat_dist, latencies, scpu, 0])

        ops = ops + 1
        t2 = time.time()
        latency = t2 - t1
        min, max, tot = latcalc(latency, min, max, tot, lat_dist)
        latencies.append(latency)

        tries = connection.attempts
        retries += tries - 1
        if debug & 32:
            print "%f  %f  TransID: %s Latency: %9.6f  Tries: %d %s/%s" % \
                (t1, t2, transID, latency, tries, cname, objname)

        if logmask & 1 or (logmask & 4 and latency > sizelat[sizenum]):
            logger(2, "%f  %f  %s  %s/%s" % \
                       (t1, latency, transID, cname, objname), instance)

    elapsed = time.time() - t0
    logger(3, 'Done!  time: %f ops: %d errs: %d' % \
               (elapsed, ops, errs), instance)
    logger(9, '', instance)

    return(['del', instance, elapsed, ops, min, max, \
                tot, errs, lat_dist, latencies, scpu, retries])


def delcont(connection, cname):
    """
    delete specified container, noting this is a cleanup function
    and NOT a test
    """

    try:
        connection.delete_container(cname)
    except ClientException as err:
        if err.http_status == 409:
            print "container %s is not empty and so couldn't delete" % cname
        else:
            print 'error %d deleting container %s' % (err.http_status, cname)
    except Exception as err:
        import traceback
        logexec('get_object() except: %s %s' % (err, traceback.format_exc()))
        logger(9, '', instance)
        print 'Unexpected Error - delete_container() exception: %s' % err


def ptime(secs):
    """
    convert time in UTC to a string of the form HH:MM:SS
    """

    string = time.ctime(secs)
    strings = string.split()
    return(strings[3])


def read_stat():
    """
    read current CPU times from /proc/stat
    """

    stats = open('/proc/stat', 'r')
    for line in stats:
        if re.match('cpu ', line):
            break

    stats.close()
    return(line.rstrip())


def execute_proc(args):
    """
    execute specified test for 1 process
    """

    instance = args[0]
    preauthurl = args[1]
    preauthtoken = args[2]
    cname = args[3]
    csize = args[4]
    oname = args[5]
    numobj = args[6]
    test = args[7]
    stime = args[8]

    # for PUTs, last will already be correct but we're also passed the correct
    # numbers anyways. but for other operations last is still pointing to the
    # reqested PUTs and not the real ones which would be different if
    # --runtime used
    last[instance] = numobj

    #    C o n n e c t

    # if connecting directly to a proxy, we need to build
    # the preauthurl in a round-robin fashion
    if len(proxies):
        proxy_index = (instance + int(options.rank)) % \
            len(proxies)
        proxy = proxies[proxy_index]
        preauthurl = reset_url(preauthurl, proxy)
        if debug & 64:
            print "Proxy Connect, resetting preauthurl to", preauthurl

    if debug & 64:
        print "*** Actual Connect using preauthurl/preauthtokens"
    connection = connect(authurl, username, password, osvars, \
                             preauthurl, preauthtoken)
    if connection == -1:
        return(['Error: ClientException connect error'])
    logexec('connected')

    #     D e l a y    U n t i l    s y n c t i m e    i f    s p e c i f i e d

    # we only honor --sync for the first of a set of tests
    if first_test and options.synctime:
        wait = int(options.synctime) - time.time()
        if debug & 1:
            print "Sync: %s Wait: %f" % (options.synctime, wait)
        if wait > 0:
            # this is a lot more work than it should be.  it seems that
            # stalls of more then 10 seconds between the initial connection
            # and put/get/whatever, cause a 1 second latency.  so until fixed
            # we neen to make sure we never sleep more than 10 seconds w/o
            # some activity over the connection
            while time.time() < int(options.synctime):
                sleeptime = int(options.synctime) - time.time()
                if sleeptime > 8:
                    sleeptime = 8
                time.sleep(sleeptime)

                # should't take more than a few msec, but we're not
                # doing anything else at the moment so let's be sure
                if int(options.synctime) - time.time() > 2:
                    headers = connection.head_account()
        else:
            if not options.quiet:
                print "warning: Sync time passed..."

            # if we need to exit on this warning we need to make sure
            # output populated or bad things will happen later
            if options.warnexit:
                lat_dist = []
                for i in range(11):
                    lat_dist.append(0)
                return([test, instance, 0, 0, 0, 0, 0, 0, 0, \
                               lat_dist, read_stat()])

    if options.runtime:
        donetime = time.time() + int(options.runtime)
    else:
        donetime = 9999999999

    # turns out that some tests can take longer than the PUT, and since we
    # want to access all the objects, double our run time which should be
    # enough time for the other tests to complete
    if re.search('p', options.tests) and test != 'p':
        donetime *= 2

    #    R u n    1    T e s t

    if debug & 1:
        print "Start Test for %s - cname: %s  csize: %d  oname: %s range: %s" % \
            (test, cname, csize, oname, options.range)

    random_flag = False
    if re.match('[PGD]', test):
        random_flag = True

    if test == 'p' or test == 'P':
        logexec('begin PUT %d' % instance)
        output = put(connection, instance, donetime, cname, \
                         csize, oname, random_flag)
        logexec('PUT %d completed' % instance)
    elif test == 'g' or test == 'G':
        logexec('begin GET %d' % instance)
        output = get(connection, instance, donetime, cname, \
                         csize, oname, random_flag)
        logexec('GET %d completed' % instance)
    elif test == 'd' or test == 'D':
        logexec('begin DEL %d' % instance)
        output = delobj(connection, instance, donetime, cname, \
                         csize, oname, random_flag)
        logexec('DEL %d completed' % instance)
    else:
        error("Invalid test: %s" % test)

    if debug & 1:
        print "Test done for instance", instance

    connection.close()

    return(output)


def print_line(procs, instance, ops, rate, iops, min, max, tot, errs,
               cpu_percent, lat_dist, median, etime, retries, psum_flag=False):
    """
    print a line of results for one process OR total for all, only printing
    process details when --psum set and print_output tells us to do so
    """

    # convert procs to a string so we can print a '-' for --psum
    if not psum_flag:
        pstring = '%s' % procs
    else:
        pstring = '-'

    # relatively rare, but if no ops, no latencies...
    if ops:
        latency = "%7.3f" % float(tot / ops)
    else:
        latency = '000.00'
        min = max = 0
        for i in range(11):
            lat_dist.append(0)

    if test == 'p':
        tname = 'put'
    elif test == 'P':
        tname = 'putR'
    elif test == 'g':
        tname = 'get'
    elif test == 'G':
        tname = 'getR'
    elif test == 'd':
        tname = 'del'
    elif test == 'D':
        tname = 'delR'

    line = ''
    if options.rank:
        line += "%-4s " % options.rank
    line += "%-4s  %4d %4s %6s  %8s  %8s %8.2f %5d" % \
        (tname, 1, procs, cvt2KMG(osize), ptime(stime), ptime(etime), \
             rate, ops)
    line += "%10.2f %4d %s %7.3f %5.2f-%05.2f" % \
        (iops, errs, latency, median, min, max)
    if options.ldist:
        for i in range(11):
            line += " %5d" % lat_dist[i]

    line += "  %5.2f" % cpu_percent
    if options.utc:
        line += ' %d' % ttime
    line += ' %3d' % retries
    print line


def median_calc(list):
    """
    Calculate the median of a list
    """

    list.sort()
    return(list[len(list) / 2])


def print_output(results, procs):
    """
    print header AND generate results for 1 process or summarize all,
    calling print_line() for each
    """

    global header_printed

    #    P r i n t    H e a d e r

    # only makes sense to suppress when running from a master control script
    header = ''
    if not options.nohead and not header_printed:
        if options.rank:
            header += "%4s " % 'Rank'

        header += "%4s  %4s %4s %6s  %-8s  %-8s %8s %5s" % \
            ('Test', 'Clts', 'Proc', 'OSize', 'Start', 'End', 'MB/Sec', 'Ops')
        header += "%10s %4s %7s %7s  %10s" % \
            ('Ops/Sec',  'Errs', 'Latency', 'Median', 'LatRange')

        if options.ldist:
            for i in (0, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50):
                f10 = "%.*f" % (int(options.ldist), float(i) / ldist10)
                header += " %5s" % f10
        header += '   %CPU'
        if options.utc:
            header += ' %-10s' % 'Timestamp'
        header += ' Ret'
        print header
        header_printed = 1

    #    C a l c u l a t e    C P U    U t i l

    # first, find the oldest CPU counters based on which process started
    # first by seeing who has the lowest user time
    oldest = 9999999999
    for i in range(procs):
        scpu = results[i][10]
        user = int(scpu.split()[1])
        if user < oldest:
            cpu_start = scpu
            oldest = user

    # now get current CPU counters
    cpu_end = read_stat()
    cpus = cpu_start.split()
    cpue = cpu_end.split()

    # note that the total includes idle and iowait time
    cpu_real = cpu_total = 0
    for i in range(1, 8):
        diff = int(cpue[i]) - int(cpus[i])
        cpu_total = cpu_total + diff
        if i != 4 and i != 5:
            cpu_real = cpu_real + diff
    try:
        # I've seen failures when sync time passed and CPU elapsed = 0
        cpu_percent = 100.0 * cpu_real / cpu_total
    except ZeroDivisionError:
        cpu_percent
    #print "CPU - Real: %d  Tot: %d" % (cpu_real, cpu_total)

    #    D e a l    W i t h    E a c h    P r o c e s s

    ldist_tot = []
    for i in range(11):
        ldist_tot.append(0)

    errors = 0
    lattot = 0
    latmin = 999
    latmax = 0
    lat_all = []
    etime = time.time()
    opst = ratet = iopst = retries = 0
    for i in range(procs):
        oper, instance, elapsed, ops, min, max, tot, errs, \
            lat_dist, latencies, scpu, retries = results[i]

        # combine all latencies into oen big array
        lat_all += latencies

        bytes = ops * osize
        try:
            rate = bytes / elapsed / 1024 / 1024
            iops = ops / elapsed
        except ZeroDivisionError:
            rate = iops = 0

        if options.psum:
            print_line(instance, instance, ops, rate, iops, min, max,
                       tot, errs, cpu_percent, lat_dist,
                       median_calc(latencies), etime, retries, True)

        opst += ops
        ratet += rate
        iopst += iops
        errors += errs
        lattot += tot

        # even if we don't need it
        for i in range(11):
            ldist_tot[i] += lat_dist[i]

        if min < latmin:
            latmin = min
        if max > latmax:
            latmax = max
        i = i + 1

    # Final tally, always 1 greater than last one but if no iops,
    # no median value
    if iopst:
        median = median_calc(lat_all)
    else:
        median = 0

    print_line(procs, instance + 1, opst, ratet, iopst, latmin, latmax,
               lattot, errors, cpu_percent, ldist_tot, median, etime, retries)


def control_c_handler(signal, frame):

    # on ^C, just use a big stuck and whack the parent and that will
    # bring down all the children.
    os.kill(ppid, 9)
    sys.exit(0)

#####################################
#    S T A R T    O F    S C R I P T
#####################################

global header_printed

if __name__ == "__main__":

    version = '0.2.3'
    copyright = 'Copyright 2015 Hewlett-Packard Development Company, L.P.'

    # Needs to be defined before anything else for error logging
    hostname = socket.gethostname()

    # need to differentiate initial call to main from those that are called
    # when parsing args during multiprocessing
    main(sys.argv[1:])

    policy = options.policy

    # we need to know which version of disable.warnings to call
    urlloc = 0
    try:
        import urllib3
        urlloc += 1
    except:
        pass
    try:
        from requests.packages import urllib3
        urlloc += 2
    except:
        pass

    # older versions of urlib3, which may be part of requests
    # will givesub-optimal small obj performance
    urlver = urllib3.__version__
    fields = urlver.split('.')
    if fields[0] == 'dev' or int(fields[0]) == 1 and int(fields[1]) < 8:
        print "WARNING: your are running version '%s' of urllib3" % urlver
        print "         which may cause small objects operations to run slower"
        print "         it is recommended you run pip install --upgrade urllib3"

    # disable requests library warning when using --insecure
    if options.insecure == True:
        try:
            if urlloc & 1:
                urllib3.disable_warnings()
            elif urlloc & 2:
                requests.packages.urllib3.disable_warnings()
        except AttributeError:
            pass

    # make sure log ALWAYS exists before starting
    if options.exclog and (excopt == 'c' or not os.path.exists(exclog)):
        exc = open(exclog, 'w')
        exc.close()

    # flat hierarchies as special
    if re.search('f', options.objopts):
        if not options.nobjects:
            text = "-n required for flat hierarchies."
            text += "  -r ok too but there will be holes!"
            error(text)

    if re.search('a', options.objopts):
        if re.search('P', options.tests):
            error("append mode makes no sense for random PUTs")
        elif not re.search('f', options.objopts):
            error("append mode only supported for flat hierarchies. " + \
                      "consider different onames OR --objopts u")

    sleep_test = sleep_testset = sleep_proc = 0
    if options.sleeps:
        options.sleeps += '::'    # makes sure aways at least 3
        fields = options.sleeps.split(':')
        try:
            if fields[0] != '':
                sleep_test = int(fields[0])
            if fields[1] != '':
                sleep_testset = int(fields[1])
            if fields[2] != '':
                sleep_proc = int(fields[2])
        except ValueError:
            error('non-numeric value in --sleeps')

    #     C r e a t e    L o c a l    C o n n e c t i o n

    # multiprocessing/ssl doesn't like to use the same connections in the
    # parent and child processes, so create one here for us to use.
    # also use this opportunity to get a single auth token/url pair for
    # everyone to share
    proxies = []
    preauthurl = ''
    if debug & 64:

        # a lot of extra work but I want to know when proxies are involved
        header_printed = False
        for env in os.environ:
            if re.search('proxy', env):
                if not header_printed:
                    print "*** Proxy environment variables ***"
                    header_printed = True
                print "%s=%s" % (env, os.environ.get(env))

        print "*** Initial Connect - get preauthtoken/preauthurl"
    connection = connect(authurl, username, password, osvars)
    if connection == -1:
        error('Error: ClientException connect error')
    preauthtoken = connection.token
    preauthurl = connection.url

    if debug & 64:
        print "  Got - Auth: %s  Url: %s" % (preauthtoken, preauthurl)

    preauthurl = reset_url(preauthurl)

    # only if explicitly overriding
    if options.preauthtoken:
        preauthtoken = options.preauthtoken

    # when talking directly to proxies, build a list of the
    # addresses to talk to for later use
    if options.proxies != '':

        # find the address we're currently pointing to add to the
        # no_proxy env we're building just in case proxies are set
        match = re.search('//(.*):', authurl)
        authaddr = match.group(1)
        no_proxy = '127.0.0.1,localhost,%s' % authaddr
        for addr in options.proxies.split(','):
            proxies.append(addr)
            no_proxy += ',%s' % addr
        os.environ['no_proxy'] = no_proxy
        if debug & 1:
            print "Defining no_proxy:",  os.environ['no_proxy']

    if options.repeats:
        repeats = int(options.repeats)
    else:
        repeats = 1

    try:
        fields = options.logops.split(':')
        logmask = int(fields[0])
    except:
        error('--logops must be an integer')

    if logmask & 4:
        sizelat = []
        sizes = len(sizeset)
        opslat = len(fields) - 1
        if opslat > 1 and opslat != sizes:
            error("you have specified more then one latency with opslogs " + \
                      "but their count doesn't match number of sizes")
        for i in range(sizes):
            try:
                if opslat == ':1':
                    sizelat.append(float(fields[1]))
                else:
                    sizelat.append(float(fields[i + 1]))
            except:
                error("--logops 4 must include ':val' for latency exceptions")

    logexec('Beginning execution for procset: %s' % options.procset)

    if options.echo:
        print '#',
        for i in range(len(sys.argv)):
            print '%s '% sys.argv[i],
        print

    # save our pid which is parent to the subprocesses and set a ^C handler
    ppid = os.getpid()
    signal.signal(signal.SIGINT, control_c_handler)

    last_size = 0
    first_test = 1
    header_printed = 0
    for rep in range(repeats):

        for procnum in range(len(procset)):
            procs = procset[procnum]

            logexec('Running tests for %d procs' % procs)

            # this resets last[] for the upcoming set of tests and start a
            # a new section of output with a new header unless --repeat
            reset_last(procs)

            if repeats == 1:
                header_printed = 0

            for sizenum in range(len(sizeset)):
                size = sizeset[sizenum]
                osize = cvtFromKMG(size)

                # see if we need to build a new test object
                if osize != last_size:
                    fixed_object = build_object()
                    last_size = osize

                puts_per_proc = []

                tests = options.tests.split(',')
                for testnum in range(len(tests)):
                #for test in options.tests.split(','):
                    test = tests[testnum]

                    # what time with execution actually start?
                    if options.synctime:
                        stime = int(options.synctime)
                    else:
                        stime = time.time()

                    # and the timestamp is tricky.  For PUT test, it's the test
                    # time.  For all others if the container ends in what looks
                    # like a utc time, use that.
                    log_time = stime
                    if test != 'p' and re.search('-\d{10}$', options.cname):
                        log_time = options.cname.split('-')[-1]

                    # we want the logs to match the test time for easy ident
                    # and also need to preallocate the list of log file handles
                    if logmask:
                        logfiles = []
                        for i in range(1, procs + 1):
                            logfiles.append(0)
                            logger(1, test, i - 1, log_time)

                    jobs = []
                    pool = Pool(procs)
                    inputs = []
                    csize = last_size = 0
                    create_container = 0
                    created = {}
                    cpolicy = ''
                    for inst in range(procs):
                        puts_per_proc.append(0)    # preallocate
                        if test == 'p' or not re.search('p', options.tests):
                            ttime = stime    # all tests get same ttime w/ UTC
                            numobj = last[inst]
                        else:
                            numobj = puts_per_proc[inst]

                        if debug & 16:
                            print "Exec - I: %d Obj: %d Test: %s Time: %f" % \
                                (inst, numobj, test, stime)

                        cname = options.cname
                        if options.utc:
                            cname += '-%d' % ttime
                        if options.ctype == 'bynode':
                            cname += "-%s" % options.rank
                        elif options.ctype == 'byproc':
                            cname += "-%s-%d" % (options.rank, inst)

                        # if container exists, get its storage policy name
                        # noting since they all MUST be the same we need only
                        # look at first instance
                        if inst == 0:
                            try:
                                response = {}
                                headers = connection.head_container(cname)
                                try:
                                    cpolicy = headers['x-storage-policy']
                                except KeyError:    # must be pre-juno swift
                                    if policy != '':
                                        text = "this version of swift doesn't "
                                        text += "support storage policies"
                                        error(text)

                            except ClientException as err:
                                if err.http_status != 404:
                                    error("Error %s trying to access '%s'" %
                                          (err.http_status, cname))

                            # if a storage policy specified and the container
                            # exists, they MUST match
                            if policy != '' and cpolicy != '' and \
                                    cpolicy.lower() != policy.lower():
                                error('container storage policy for %s already set to %s'
                                      % (cname, cpolicy))

                        # make sure container for get/delete tests exist
                        # before proceeding, which means we found cpolicy
                        # above.  appending on PUT will be dealt with later.
                        if re.search('[gGdD]', test) and cpolicy == '':
                            error("container '%s' doesn't exist" % cname)

                        # if not doing random or flat object I/O, oject names
                        # all start with base-rank-inst
                        oname = options.oname
                        if re.search('u', options.objopts):
                            oname += '-%d' % ttime
                        if not re.match('[PGD]', test) and \
                                not re.search('f', options.objopts):
                            oname += "-%s-%d" % (options.rank, inst)

                        if debug & 8:
                            print 'debug: cname %s  oname: %s' % (cname, oname)

                        # for flat hierarchies or when in append mode (which
                        # assumes flat hierarchies), we need to know if
                        # container exists and if so, how many objects.
                        # since all procs for shared|bynode write to container
                        # of same name we only check size once.  also note
                        # each client does this check so if something does go
                        # wrong you can get multiple errors
                        if re.search('[af]', options.objopts):
                            if inst == 0 or options.ctype == 'byproc':
                                try:
                                    headers = \
                                        connection.head_container(cname)
                                    csize = int(headers['x-container-object-count'])
                                except ClientException as err:
                                    if err.http_status == 404 and \
                                            not cname in created:
                                        warn = "warning: creating '%s'" % cname
                                        warn += " in append mode"
                                        print warn
                                        created[cname] = ''
                                    else:
                                        etype = "head_container error: "
                                        error("%s %s on '%s" % \
                                                  (etype, err, cname))

                        # make sure container(s) exits BEFORE tests start,
                        # noting append mode sets csize IF continer exists
                        # AND if a storage policy, set it
                        if test == 'p' and csize == 0:
                            if inst == 0 or options.ctype == 'byproc':
                                try:
                                    # in case a lot of containers, stagger
                                    # creation to be safe, but not too much
                                    time.sleep(.01)
                                    logexec('Create container %d' % inst)
                                    create_container = 1
                                    headers = {}
                                    if policy != '':
                                        headers ['X-Storage-Policy'] = policy
                                    connection.put_container(cname, headers=headers)
                                    logexec('container %d created' % inst)
                                except Exception as err:
                                    if err.http_status == 409:
                                        error("Error: 409 Container: %s.  Could be policy mismatch" % cname)

                                    match = re.search('Bad Request\s+(.*)', '%s' % err)
                                    if match:
                                        error('Bad Request: %s' % match.group(1))

                                    # unexpected error handling...
                                    import traceback
                                    logexec('put_container except: %s %s' % \
                                                (err, traceback.format_exc()))
                                    error('Error: put_container exc: %s' % err)

                        inputs.append([inst, preauthurl, preauthtoken, cname, \
                                           csize, oname, numobj, test, stime])

                    poolOutputs = pool.map(execute_proc, inputs)
                    pool.close()
                    pool.join()
                    first_test = 0

                    results = []
                    total_errors = 0
                    unexpected_error = 0
                    for i in range(procs):
                        logexec('I: %s' % i)
                        oneproc = poolOutputs[i]
                        if re.search('error', oneproc[0], re.IGNORECASE):
                            print "%s, try -d128 for more clues " % oneproc[0],
                            print "in /tmp on remote node"
                            unexpected_error = 1
                            break

                        results.append(oneproc)
                        logexec('I: %s got output %s' % (i, oneproc[0]))
                        total_errors += oneproc[7]
                        logexec('Count Errors: %d' % total_errors)

                        # for PUT test save number of objs actually written in
                        # case we terminated due to a timer rather than count
                        if test == 'p':
                            instance = oneproc[1]
                            nobjects = oneproc[3]
                            puts_per_proc[instance] = nobjects

                    if unexpected_error:
                        continue

                    print_output(results, procs)
                    logexec('printing complete')

                    if test == 'p' and options.putsperproc:
                        ppp = ''
                        for puts in puts_per_proc:
                            ppp += '%d:' % puts
                        print "PutsPerProc: %s" % ppp[:-1]

                    # unless --cont-nodelete, delete container(s) after
                    # delete test run
                    if test == 'd' and not options.cont_nodelete:
                        cname = options.cname
                        if options.utc:
                            cname += '-%d' % ttime
                        if options.ctype == 'bynode':
                            cname += "-%s" % options.rank
                        if debug & 1:
                            print 'deleting container(s): %s' % cname

                        if options.ctype != 'byproc':
                            delcont(connection, cname)
                        else:
                            for proc in range(procs):
                                name = '%s-%s-%d' % (cname, options.rank, proc)
                                delcont(connection, name)

                    # not sure if I should do this last, but I think I'd like
                    # to let all processes finish as well as all prints to
                    # complete before aborting, which is what warnproc means
                    if total_errors > 0 and options.warnexit:
                        sys.exit()

                    # on the very last test, skip sleep, noting if no sleeps
                    # the sleep times are all zeros
                    if testnum == len(tests) - 1 and \
                            sizenum == len(sizeset) - 1 and \
                            procnum == len(procset) - 1:
                        continue

                    if sleep_test:
                        if debug & 256:
                            print "End-of-test, sleeping", sleep_test
                        time.sleep(sleep_test)

                # on the last testset, skip sleep
                if sizenum == len(sizeset) - 1 and procnum == len(procset) - 1:
                    continue

                if sleep_testset:
                    if debug & 256:
                        print "End-of-testset, sleeping:", sleep_testset
                    time.sleep(sleep_testset)

            # on the last proc, skip sleep
            if procnum == len(procset) - 1:
                continue

            if sleep_proc:
                if debug & 256:
                    print "End-of-proc, sleeping:", sleep_proc
                    time.sleep(sleep_proc)

    logexec('processing complete')
